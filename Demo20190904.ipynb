{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Naive Bayes 建立分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_excel('data/yahoo_movie.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>不知道耶! 看完整個無感\\r\\n有種覺得就是女兒\"給蕭\"害死了老爸\\r\\n然後...既然可以...</td>\n",
       "      <td>3</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>soso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>很好看的動作片，不會浪費錢跟時間。很久沒有這樣的探險片。可說是女版的印第安那瓊。女主角跟爸爸...</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>說這個不好看的話，那我還真不知道，還有什麼片是您可以去看得了。電影好看，但話說羅拉有裝可以撿...</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>父女重逢真的很讓人感動，五顆星。</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>劇情雖然老套，但仍拍出新意，古墓能殺人的方式不就是機關和毒，要求亂七八糟的觀眾，你看喪尸片看多了。</td>\n",
       "      <td>4</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  stars title status\n",
       "0  不知道耶! 看完整個無感\\r\\n有種覺得就是女兒\"給蕭\"害死了老爸\\r\\n然後...既然可以...      3  古墓奇兵   soso\n",
       "1  很好看的動作片，不會浪費錢跟時間。很久沒有這樣的探險片。可說是女版的印第安那瓊。女主角跟爸爸...      5  古墓奇兵   good\n",
       "2  說這個不好看的話，那我還真不知道，還有什麼片是您可以去看得了。電影好看，但話說羅拉有裝可以撿...      5  古墓奇兵   good\n",
       "3                                   父女重逢真的很讓人感動，五顆星。      5  古墓奇兵   good\n",
       "4  劇情雖然老套，但仍拍出新意，古墓能殺人的方式不就是機關和毒，要求亂七八糟的觀眾，你看喪尸片看多了。      4  古墓奇兵   good"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "corpus = []\n",
    "tags   = []\n",
    "for rec in df[df['status'].isin(['good', 'bad'])].iterrows():\n",
    "    corpus.append(' '.join(jieba.cut(rec[1].content)))\n",
    "    tags.append(rec[1].status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很 好看 的 動作片 ， 不會 浪費 錢 跟 時間 。 很 久 沒有 這樣 的 探險 片 。 可 說 是 女版 的 印第安那 瓊 。 女 主角 跟 爸爸 還 有 反派 都 演 得到 位 。 陸任 的 男 配角 常 在 港片 看到 ， 很帥 。 一時 忘了 名字 。 希望 有 續集 。'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 4839)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, tags, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(test_y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51, 30],\n",
       "       [26, 89]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度學習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(e):\n",
    "    return np.exp(e) / np.exp(e).sum() \n",
    "    \n",
    "import numpy as np\n",
    "a = np.array([2,7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00667641, 0.99086747, 0.00245611])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([0.00667641, 0.99086747, 0.00245611])\n",
    "b.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00667641, -0.00913253,  0.00245611])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([0,1,0])\n",
    "b - c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(x):\n",
    "    return 1/ (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "import numpy as np\n",
    "a = np.array([2,7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88079708, 0.99908895, 0.73105858])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_function(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝 GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: requests in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: boto3 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: boto>=2.32 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: botocore<1.5.0,>=1.4.1 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from botocore<1.5.0,>=1.4.1->boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: docutils>=0.10 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from botocore<1.5.0,>=1.4.1->boto3->smart-open>=1.7.0->gensim)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim 使用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'you say goodby and i say hello .'\n",
    "\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec([s.split()], min_count=1, size=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1294edb70>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13190594,  0.11762448, -0.00629038],\n",
       "       [-0.06928848,  0.12338193, -0.01034341],\n",
       "       [-0.14628631, -0.14990619, -0.13047887],\n",
       "       [ 0.1657063 , -0.03076699, -0.09294317],\n",
       "       [-0.14430211,  0.16298111, -0.10189454],\n",
       "       [-0.08324675,  0.04580065, -0.10287556],\n",
       "       [-0.00766116, -0.12512954,  0.13616468]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': <gensim.models.keyedvectors.Vocab at 0x129553048>,\n",
       " 'say': <gensim.models.keyedvectors.Vocab at 0x129553208>,\n",
       " 'goodby': <gensim.models.keyedvectors.Vocab at 0x129553240>,\n",
       " 'and': <gensim.models.keyedvectors.Vocab at 0x1295532b0>,\n",
       " 'i': <gensim.models.keyedvectors.Vocab at 0x1295532e8>,\n",
       " 'hello': <gensim.models.keyedvectors.Vocab at 0x129553320>,\n",
       " '.': <gensim.models.keyedvectors.Vocab at 0x129553358>}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'you say goodby and i say hello .'\n",
    "\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec([s.split()], min_count=1, size=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19785893,  0.17643672],\n",
       "       [-0.10393272,  0.18507288],\n",
       "       [-0.21942945, -0.22485928],\n",
       "       [ 0.24855947, -0.04615048],\n",
       "       [-0.21645318,  0.24447167],\n",
       "       [-0.12487013,  0.06870098],\n",
       "       [-0.01149174, -0.18769431]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['you', 'say', 'goodby', 'and', 'i', 'hello', '.'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12c1139e8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADzBJREFUeJzt3U9sndWZx/HvM07SsTRqDcUKiUMIo0aWUlER6Ta7gQWpHGZBLESnUNEGiVFWrCpZShSJBRvaetFuWBAxlVKkig5RGqI2rQVpF12UDqauiMLIJEUtxAkkZeqqGu6UJDyz8HW4cez4z/3n3PP9SFd+3/Me3fOcRP7d1+e9972RmUiSyvIPnS5AktR+hr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQGs6XcBCbrvtttyyZUuny5Ckm8obb7zx58zsX6zfqg3/LVu2MD4+3ukyJOmmEhF/Wko/l30kqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCrdp7+7TC0YkpRscmOTddZWNfLyNDgwxvH+h0WZLUdsWE/9GJKfYfOUn10hUApqar7D9yEsAXAEnFKWbZZ3Rs8mrwz6peusLo2GSHKpKkzikm/M9NV5fVLkndrJjw39jXu6x2SepmxYT/yNAgvWt7rmnrXdvDyNBghyqSpM4p5oLv7EVd3+0jSQWFP8y8ABj2klTQso8k6VOGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalATQn/iNgVEZMRcSYi9s1z/FsR8VZEvBkRJyLizmaMK0lamYbDPyJ6gGeBB4BtwKMRsW1OtwmgkplfAg4D3210XEnSyjXjzH8HcCYz38nMj4EXgd31HTLzV5n5UW33NWBTE8aVJK1QM8J/AHivbv9srW0hTwA/n+9AROyNiPGIGL948WITSpMkzaetF3wj4jGgAozOdzwzD2ZmJTMr/f397SxNkorSjFs6TwF31O1vqrVdIyJ2AgeA+zLz700YV5K0Qs0I/9eBrRFxFzOh/wjw9foOEbEdeA7YlZkXmjCmmuzoxJRfdCMVpOHwz8zLEfEkMAb0AD/IzFMR8TQwnpnHmFnm+SfgpYgAeDczH2x0bDXH0Ykp9h85SfXSFQCmpqvsP3ISwBcAqUs15Zu8MvM4cHxO21N12zubMY5aY3Rs8mrwz6peusLo2KThL3UpP+Erzk1Xl9Uu6eZX1Hf4Llcp6+Ab+3qZmifoN/b1dqAaSe3gmf8CZtfBp6arJJ+ugx+duO6NTDe9kaFBetf2XNPWu7aHkaHBDlUkqdUM/wXcaB282wxvH+CZh+5moK+XAAb6ennmobu78q8cSTNc9llAaevgw9sHDHupIJ75L2Ch9W7XwSV1A8N/Aa6DS+pmLvssYHYJpIR3+0gqj+F/A66DS+pWLvtIUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCNSX8I2JXRExGxJmI2DfP8Xsj4ncRcTkiHm7GmJKklWs4/COiB3gWeADYBjwaEdvmdHsXeBz4UaPjSZIat6YJz7EDOJOZ7wBExIvAbuCt2Q6Z+cfasU+aMJ4kqUHNWPYZAN6r2z9ba1u2iNgbEeMRMX7x4sUmlCZJms+quuCbmQczs5KZlf7+/k6XI0ldqxnhPwXcUbe/qdYmSVqlmhH+rwNbI+KuiFgHPAIca8LzSpJapOHwz8zLwJPAGPDfwH9m5qmIeDoiHgSIiC9HxFngq8BzEXGq0XElSSvXjHf7kJnHgeNz2p6q236dmeUgSdIqsKou+EqS2sPwl6QCGf6SVCDDX5IK1JQLvlpdjk5MMTo2ybnpKhv7ehkZGmR4+4o+dC2pSxn+XeboxBT7j5ykeukKAFPTVfYfOQngC4Ckq1z26TKjY5NXg39W9dIVRscmO1SRpNXI8O8y56ary2qXVCbDv8ts7OtdVrukMhn+XWZkaJDetT3XtPWu7WFkaLBDFUlajbzg22VmL+r6bh9JN2L4d6Hh7QOGvaQbctlHkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBmhL+EbErIiYj4kxE7Jvn+Gci4se147+NiC3NGFeStDINh39E9ADPAg8A24BHI2LbnG5PAH/JzC8A3wO+0+i4kqSVa8aZ/w7gTGa+k5kfAy8Cu+f02Q0cqm0fBu6PiGjC2JKkFWhG+A8A79Xtn621zdsnMy8DfwU+34SxJUkrsKou+EbE3ogYj4jxixcvdrocSepazQj/KeCOuv1NtbZ5+0TEGuBzwIdznygzD2ZmJTMr/f39TShNkjSfZoT/68DWiLgrItYBjwDH5vQ5BuypbT8M/DIzswljS5JWYE2jT5CZlyPiSWAM6AF+kJmnIuJpYDwzjwH/AbwQEWeA/2HmBUKS1CENhz9AZh4Hjs9pe6pu+/+ArzZjLElS41bVBV9JUnsY/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVKCm3N5BkrR0RyemGB2b5Nx0lY19vYwMDTK8fe7XoLSW4S9JbXR0Yor9R05SvXQFgKnpKvuPnARo6wuAyz6S1EajY5NXg39W9dIVRscm21qH4S9JbXRuurqs9lYx/CWpjTb29S6rvVUMf0lqo5GhQXrX9lzT1ru2h5GhwbbW4QVfSWqj2Yu6vttHkgozvH2g7WE/l8s+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBWoo/CPi1oh4JSJO137eskC/X0TEdET8tJHxJEnN0eiZ/z7gRGZuBU7U9uczCnyjwbEkSU3SaPjvBg7Vtg8Bw/N1yswTwN8aHEuS1CSNhv/6zDxf234fWN/g80mS2mDRb/KKiFeB2+c5dKB+JzMzIrKRYiJiL7AXYPPmzY08lSTpBhYN/8zcudCxiPggIjZk5vmI2ABcaKSYzDwIHASoVCoNvZBIkhbW6LLPMWBPbXsP8HKDzydJaoNGw//bwFci4jSws7ZPRFQi4vnZThHxa+Al4P6IOBsRQw2OK0lqwKLLPjeSmR8C98/TPg78e93+vzQyjiSpufyEryQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUoDWdLkBqp6MTU4yOTXJuusrGvl5GhgYZ3j7Q6bKktjP8VYyjE1PsP3KS6qUrAExNV9l/5CSALwAqjss+Ksbo2OTV4J9VvXSF0bHJDlUkdY7hr2Kcm64uq13qZg2Ff0TcGhGvRMTp2s9b5ulzT0T8JiJORcSbEfG1RsaUVmpjX++y2qVu1uiZ/z7gRGZuBU7U9uf6CPhmZn4R2AV8PyL6GhxXWraRoUF61/Zc09a7toeRocEOVSR1TqPhvxs4VNs+BAzP7ZCZb2fm6dr2OeAC0N/guNKyDW8f4JmH7magr5cABvp6eeahu73YqyI1+m6f9Zl5vrb9PrD+Rp0jYgewDvhDg+NKKzK8fcCwl1hC+EfEq8Dt8xw6UL+TmRkReYPn2QC8AOzJzE8W6LMX2AuwefPmxUqTJK3QouGfmTsXOhYRH0TEhsw8Xwv3Cwv0+yzwM+BAZr52g7EOAgcBKpXKgi8kkqTGNLrmfwzYU9veA7w8t0NErAN+AvwwMw83OJ4kqQkaDf9vA1+JiNPAzto+EVGJiOdrff4NuBd4PCJ+X3vc0+C4kqQGRObqXF2pVCo5Pj7e6TIk6aYSEW9kZmWxfn7CV5IKVMSN3byToyRdq+vD3zs5StL1un7Zxzs5StL1uj78vZOjJF2v68PfOzlK0vW6Pvy9k6MkXa/rL/jOXtT13T6S9KmuD3/wTo6SNFfXL/tIkq5n+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kq0Kr9AveIuAj8qcNl3Ab8ucM1dIpzL0+p84bumvudmdm/WKdVG/6rQUSMZ2al03V0gnMvb+6lzhvKnLvLPpJUIMNfkgpk+N/YwU4X0EHOvTylzhsKnLtr/pJUIM/8JalAhn+diLg1Il6JiNO1n7fM0+eeiPhNRJyKiDcj4mudqLXZljL3Wr9fRMR0RPy03TU2U0TsiojJiDgTEfvmOf6ZiPhx7fhvI2JL+6tsjSXM/d6I+F1EXI6IhztRY6ssYe7fioi3ar/bJyLizk7U2Q6G/7X2AScycytworY/10fANzPzi8Au4PsR0dfGGltlKXMHGAW+0baqWiAieoBngQeAbcCjEbFtTrcngL9k5heA7wHfaW+VrbHEub8LPA78qL3VtdYS5z4BVDLzS8Bh4LvtrbJ9DP9r7QYO1bYPAcNzO2Tm25l5urZ9DrgALPqBipvAonMHyMwTwN/aVVSL7ADOZOY7mfkx8CIz869X/+9xGLg/IqKNNbbKonPPzD9m5pvAJ50osIWWMvdfZeZHtd3XgE1trrFtDP9rrc/M87Xt94H1N+ocETuAdcAfWl1YGyxr7je5AeC9uv2ztbZ5+2TmZeCvwOfbUl1rLWXu3Wq5c38C+HlLK+qgNZ0uoN0i4lXg9nkOHajfycyMiAXfChURG4AXgD2ZeVOcITVr7lK3i4jHgApwX6draZXiwj8zdy50LCI+iIgNmXm+Fu4XFuj3WeBnwIHMfK1FpTZdM+beJaaAO+r2N9Xa5utzNiLWAJ8DPmxPeS21lLl3qyXNPSJ2MnNCdF9m/r1NtbWdyz7XOgbsqW3vAV6e2yEi1gE/AX6YmYfbWFurLTr3LvI6sDUi7qr9fz7CzPzr1f97PAz8MrvjQzFLmXu3WnTuEbEdeA54MDO7+QQIMtNH7cHMmu4J4DTwKnBrrb0CPF/bfgy4BPy+7nFPp2tvx9xr+78GLgJVZtZMhzpd+wrn+6/A28xcrzlQa3uamV96gH8EXgLOAP8F/HOna27j3L9c+7/9X2b+2jnV6ZrbOPdXgQ/qfrePdbrmVj38hK8kFchlH0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KB/h+i4gSmXiDizQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "from matplotlib import pyplot as plt\n",
    "words = list(model.wv.vocab.keys())\n",
    "for i in range(len(words)):\n",
    "    #print(words[i])\n",
    "    plt.annotate(words[i], (X[i, 0], X[i, 1]))\n",
    "plt.scatter(X[:,0], X[:,1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 0.9774017333984375),\n",
       " ('say', 0.9457564353942871),\n",
       " ('hello', 0.8493059277534485),\n",
       " ('goodby', -0.2820505201816559),\n",
       " ('and', -0.6405924558639526),\n",
       " ('.', -0.8403661847114563)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Word2Vec 進行分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_excel('data/yahoo_movie.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for e in df['content'].tolist():\n",
    "    corpus.append(list(jieba.cut(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(corpus, min_count=10, size=50, iter=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "?word2vec.Word2Vec\n",
    "#model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('糟', 0.6102331280708313),\n",
       " ('好看', 0.5784004330635071),\n",
       " ('雜亂', 0.4525483250617981),\n",
       " ('差', 0.4513176381587982),\n",
       " ('爛', 0.4500066339969635),\n",
       " ('快', 0.362907350063324),\n",
       " ('⋯', 0.3600214421749115),\n",
       " ('普通', 0.35243484377861023),\n",
       " ('還要', 0.3515854775905609),\n",
       " ('真心', 0.33277419209480286)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('難看')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install /Users/davidchiu/Desktop/gensim-3.8.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "size = 10  # 產生多少維度 \n",
    "min_count = 5 # 要算至少出現多少次數的字詞\n",
    "workers = 1 # 使用多少個core 計算, -1 使用所有的core 進行計算 \n",
    "window = 10  # 上下文的區間\n",
    "iter = 300 # 神經網路訓練的迭代數\n",
    "sample = 1e-5 # 取樣的數量\n",
    "model = word2vec.Word2Vec(corpus, \n",
    "                          workers = workers,\n",
    "                          sample = sample,\n",
    "                          size = size,\n",
    "                          min_count=min_count,\n",
    "                          window = window,\n",
    "                          iter = iter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('屌', 0.9873900413513184),\n",
       " ('氣氛', 0.987124502658844),\n",
       " ('在一起', 0.9864601492881775),\n",
       " ('值得', 0.9856245517730713),\n",
       " ('喔', 0.9851853847503662),\n",
       " ('囉', 0.9846028685569763),\n",
       " ('來', 0.9827703237533569),\n",
       " ('唯一', 0.9824857711791992),\n",
       " ('古墓', 0.9820506572723389),\n",
       " ('才', 0.9817382097244263)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('好片')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用word2vec  做文字分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_excel('data/yahoo_movie.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "corpus = []\n",
    "tags   = []\n",
    "for rec in df[df['status'].isin(['good', 'bad'])].iterrows():\n",
    "    corpus.append(list(jieba.cut(rec[1]['content'])))\n",
    "    tags.append(rec[1]['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "size = 50  # 產生多少維度 \n",
    "min_count = 5 # 要算至少出現多少次數的字詞\n",
    "workers = 1 # 使用多少個core 計算, -1 使用所有的core 進行計算 \n",
    "window = 10  # 上下文的區間\n",
    "iter = 300 # 神經網路訓練的迭代數\n",
    "sample = 1e-5 # 取樣的數量\n",
    "model = word2vec.Word2Vec(corpus, \n",
    "                          workers = workers,\n",
    "                          sample = sample,\n",
    "                          size = size,\n",
    "                          min_count=min_count,\n",
    "                          window = window,\n",
    "                          iter = iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vec = np.zeros(size).reshape((1, size))\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.14836643e-01, -3.98676539e-01,  4.36587637e-01,\n",
       "         4.32628862e-01, -2.47301055e-01, -2.14094743e-01,\n",
       "         6.36092473e-02,  4.32064281e-02,  1.25435153e-01,\n",
       "        -9.68969495e-01,  2.40403324e-01,  1.34817976e-01,\n",
       "         3.58330657e-01, -4.28311526e-01, -9.21367077e-02,\n",
       "         5.17471920e-01,  6.20584522e-02,  5.90776255e-01,\n",
       "         1.32624670e+00,  2.24248597e-01,  5.06548911e-01,\n",
       "        -6.18105982e-01,  8.20739280e-01,  6.09204746e-01,\n",
       "         5.34344771e-01, -7.29854964e-01, -2.76716522e-01,\n",
       "         1.31554507e-01,  1.38972756e-01, -6.11894508e-01,\n",
       "        -8.58816517e-01,  2.61624200e-01, -4.42699214e-01,\n",
       "         3.35187214e-01, -7.75294933e-04, -1.53520707e-01,\n",
       "        -1.25851653e-01, -6.94332820e-02,  3.63292964e-01,\n",
       "         2.74051482e-01, -3.70304758e-01, -5.61534748e-01,\n",
       "        -1.01263385e+00, -1.90275518e-02, -2.87387331e-01,\n",
       "         4.85446466e-01,  3.34943990e-01,  8.55101512e-01,\n",
       "         2.76073989e-01, -5.74011020e-01]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for w in corpus[0]:\n",
    "    if w in model:\n",
    "        #print(w, model[w])\n",
    "        vec += model[w]\n",
    "        cnt += 1\n",
    "vec / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  import sys\n",
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vecs = []\n",
    "vec = np.zeros(size).reshape((1, size))\n",
    "cnt = 0\n",
    "for s in corpus:\n",
    "    for w in s:\n",
    "        if w in model:\n",
    "            #print(w, model[w])\n",
    "            vec += model[w].reshape((1, size))\n",
    "            cnt += 1\n",
    "    vecs.append(vec / cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(vecs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 50)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, tags, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel = 'linear')\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6020408163265306"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(test_y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47, 34],\n",
       "       [44, 71]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/ab/d3bed6b92042622d24decc7aadc8877badf18aeca1571045840ad4956d3f/Werkzeug-0.15.5-py2.py3-none-any.whl (328kB)\n",
      "\u001b[K    100% |████████████████████████████████| 337kB 947kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: html5lib==0.9999999 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already satisfied: bleach==1.5.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Requirement already satisfied: setuptools in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow)\n",
      "Installing collected packages: werkzeug\n",
      "  Found existing installation: Werkzeug 0.9.6\n",
      "    Uninstalling Werkzeug-0.9.6:\n",
      "      Successfully uninstalled Werkzeug-0.9.6\n",
      "Successfully installed werkzeug-0.15.5\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n",
    "# pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-161-fbc3036e4c69>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 256 \n",
    "n_input    = 784 \n",
    "n_classes  = 10 \n",
    "n_samples  = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "    x = tf.placeholder(\"float\", [None, n_input], name= 'input_x')\n",
    "    y = tf.placeholder(\"float\", [None, n_classes], name= 'input_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input_reshape'):\n",
    "    image_input = tf.reshape(x,[-1,28,28,1])\n",
    "    tf.summary.image('input', image_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(x, input_tensors, output_tensors, layer_name, activation_function = None):  \n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            weight = tf.Variable(tf.random_normal([input_tensors, output_tensors]), name = 'w')\n",
    "            tf.summary.histogram(name = layer_name + '/Weights', values = weight)\n",
    "        with tf.name_scope('Bias'):\n",
    "            bias = tf.Variable(tf.random_normal([output_tensors]), name= 'b')\n",
    "            tf.summary.histogram(name = layer_name + '/Bias', values = bias)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            formula = tf.add(tf.matmul(x, weight), bias)\n",
    "        if activation_function is None:\n",
    "            outputs = formula\n",
    "        else:\n",
    "            outputs = activation_function(formula)\n",
    "        tf.summary.histogram(name = layer_name + '/Outputs', values = outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = add_layer(x, input_tensors = n_input, output_tensors = n_hidden_1, layer_name='layer1',activation_function = tf.nn.relu)\n",
    "layer2 = add_layer(layer1, input_tensors = n_hidden_1, output_tensors = n_hidden_2, layer_name='layer2',activation_function = tf.nn.relu)\n",
    "out_layer = add_layer(layer2, input_tensors = n_hidden_2, output_tensors = n_classes, layer_name='out_layer',activation_function = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-168-85aab1677ab7>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('cost'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=y))\n",
    "    tf.summary.scalar('loss', cost)\n",
    "    \n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    acc = tf.equal(tf.argmax(out_layer, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=153.98696717695748\n",
      "Epoch: 2 cost=59.85513640317052\n",
      "Epoch: 3 cost=44.49826552130955\n",
      "Epoch: 4 cost=36.21848631338643\n",
      "Epoch: 5 cost=30.83456163319674\n",
      "Epoch: 6 cost=26.681236736124188\n",
      "Epoch: 7 cost=23.78706894137643\n",
      "Epoch: 8 cost=21.330923768173562\n",
      "Epoch: 9 cost=19.411034850776197\n",
      "Epoch: 10 cost=17.744112639427172\n",
      "Epoch: 11 cost=16.398108545433384\n",
      "Epoch: 12 cost=15.213994324965906\n",
      "Epoch: 13 cost=14.134885062767783\n",
      "Epoch: 14 cost=13.208053894313885\n",
      "Epoch: 15 cost=12.403907239599656\n",
      "Training Completed in 15 Epochs\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    ## Merge Summary\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"tensorboard2/\", graph = sess.graph)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c,result = sess.run([optimizer, cost,merged], feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "            ## Adding summary of each step\n",
    "            writer.add_summary(result,  epoch * total_batch + i)\n",
    "\n",
    "        print(\"Epoch: {} cost={}\".format(epoch+1,avg_cost))\n",
    "\n",
    "    print(\"Training Completed in {} Epochs\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pyyaml in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from keras)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test  /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes  = 10 \n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 256 \n",
    "n_input    = 784 \n",
    "n_classes  = 10 \n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_shape=(n_input,)))\n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.0523 - acc: 0.7554 - val_loss: 0.4846 - val_acc: 0.8804\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.4222 - acc: 0.8875 - val_loss: 0.3537 - val_acc: 0.9015\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.3436 - acc: 0.9037 - val_loss: 0.3063 - val_acc: 0.9133\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3069 - acc: 0.9133 - val_loss: 0.2785 - val_acc: 0.9214\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2824 - acc: 0.9193 - val_loss: 0.2605 - val_acc: 0.9265\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2634 - acc: 0.9254 - val_loss: 0.2447 - val_acc: 0.9316\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2477 - acc: 0.9299 - val_loss: 0.2338 - val_acc: 0.9327\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2345 - acc: 0.9341 - val_loss: 0.2236 - val_acc: 0.9363\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2226 - acc: 0.9376 - val_loss: 0.2104 - val_acc: 0.9385\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2119 - acc: 0.9402 - val_loss: 0.2021 - val_acc: 0.9411\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2022 - acc: 0.9433 - val_loss: 0.1935 - val_acc: 0.9426\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1932 - acc: 0.9457 - val_loss: 0.1878 - val_acc: 0.9433\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1850 - acc: 0.9480 - val_loss: 0.1788 - val_acc: 0.9492\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1771 - acc: 0.9504 - val_loss: 0.1725 - val_acc: 0.9492\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1702 - acc: 0.9519 - val_loss: 0.1667 - val_acc: 0.9522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
