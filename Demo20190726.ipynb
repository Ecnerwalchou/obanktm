{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "b = 2\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 英文斷詞 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'this is a  book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "print(dir(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function split:\n",
      "\n",
      "split(...) method of builtins.str instance\n",
      "    S.split(sep=None, maxsplit=-1) -> list of strings\n",
      "    \n",
      "    Return a list of the words in S, using sep as the\n",
      "    delimiter string.  If maxsplit is given, at most maxsplit\n",
      "    splits are done. If sep is not specified or is None, any\n",
      "    whitespace string is a separator and empty strings are\n",
      "    removed from the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(s.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'book']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '''\n",
    "今天除了清晨中南部沿海有短暫降雨外，仍是午後雷陣雨為主的天氣型態。氣象預報員陳建安表示，因為太平洋高壓減弱，上半天各地大多為多雲，午後各地山區與近山區都要留意局部大雨跟豪雨的發生機率。加上今天風場偏西南風、水汽較多，北部、東北部地區午後雷陣雨範圍較廣，可能會影響至平地地區，提醒民眾記得攜帶雨具。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n今天除了清晨中南部沿海有短暫降雨外',\n",
       " '仍是午後雷陣雨為主的天氣型態',\n",
       " '氣象預報員陳建安表示',\n",
       " '因為太平洋高壓減弱',\n",
       " '上半天各地大多為多雲',\n",
       " '午後各地山區與近山區都要留意局部大雨跟豪雨的發生機率',\n",
       " '加上今天風場偏西南風',\n",
       " '水汽較多',\n",
       " '北部',\n",
       " '東北部地區午後雷陣雨範圍較廣',\n",
       " '可能會影響至平地地區',\n",
       " '提醒民眾記得攜帶雨具',\n",
       " '\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('，|。|、', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/davidchiu/Desktop/jieba-master.zip\n",
      "  Requirement already satisfied (use --upgrade to upgrade): jieba==0.39 from file:///Users/davidchiu/Desktop/jieba-master.zip in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages\n",
      "Building wheels for collected packages: jieba\n",
      "  Running setup.py bdist_wheel for jieba ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/davidchiu/Library/Caches/pip/wheels/be/21/28/e0bfffcff93e8c8ed12617d1c0e9db29edfe47e8b43e6f17c5\n",
      "Successfully built jieba\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install /Users/davidchiu/Desktop/jieba-master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Tokenizer.cut at 0x103c91f68>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.cut('大巨蛋案對市府同仁下封口令？　柯P否認')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋案\n",
      "對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口\n",
      "令\n",
      "？\n",
      "　\n",
      "柯P\n",
      "否認\n"
     ]
    }
   ],
   "source": [
    "seg = jieba.cut('大巨蛋案對市府同仁下封口令？　柯P否認')\n",
    "for w in seg:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method cut in module jieba:\n",
      "\n",
      "cut(sentence, cut_all=False, HMM=True) method of jieba.Tokenizer instance\n",
      "    The main function that segments an entire sentence that contains\n",
      "    Chinese characters into seperated words.\n",
      "    \n",
      "    Parameter:\n",
      "        - sentence: The str(unicode) to be segmented.\n",
      "        - cut_all: Model type. True for full pattern, False for accurate pattern.\n",
      "        - HMM: Whether to use the Hidden Markov Model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(jieba.cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "?jieba.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 大巨蛋/ 大巨蛋案/ 巨蛋/ 巨蛋案/ 蛋案/ 對/ 市府/ 同仁/ 下/ 封口/ 口令/ / / / 柯/ P/ 否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=True)\n",
    "print(\"Full Mode:\", \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 大巨蛋案/ 對/ 市府/ 同仁/ 下/ 封口/ 令/ ？/ 　/ 柯P/ 否認\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=False, HMM=False)\n",
    "print(\"Default Mode:\", \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '覺得', '這', '個', 'idea', '非常', '的', 'great']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "s = '我覺得這個idea非常的great'\n",
    "list(jieba.cut(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/46/b7dzk4mn6g54qzptv608w7d00000gn/T/jieba.cache\n",
      "Loading model cost 0.691 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 大巨蛋案/ 對/ 市府/ 同仁/ 下/ 封口令/ ？/ 　/ 柯P/ 否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=False)\n",
    "print(\"Default Mode:\", \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋案 N\n",
      "對 P\n",
      "市府 N\n",
      "同仁 N\n",
      "下 POST\n",
      "封口令 n\n",
      "？ x\n",
      "　 x\n",
      "柯P N\n",
      "否認 Vt\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "jieba.load_userdict('userdict.txt')\n",
    "words = pseg.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "for w in words:\n",
    "    print(w.word, w.flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 大巨蛋案/ 對/ 市府/ 同仁/ 下/ 封口令/ ？/ 　/ 柯P/ 否認\n"
     ]
    }
   ],
   "source": [
    "#jieba.add_word('封口令')\n",
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=False)\n",
    "print(\"Default Mode:\", \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋案 0 4\n",
      "對 4 5\n",
      "市府 5 7\n",
      "同仁 7 9\n",
      "下 9 10\n",
      "封口令 10 13\n",
      "？ 13 14\n",
      "　 14 15\n",
      "柯P 15 17\n",
      "否認 17 19\n"
     ]
    }
   ],
   "source": [
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "words = jieba.tokenize(sentence)\n",
    "\n",
    "for tw in words:\n",
    "    print(tw[0], tw[1], tw[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋案\n",
      "對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口令\n",
      "？\n",
      "　\n",
      "柯P\n",
      "否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "#sentence = '仍是午後雷陣雨為主的天氣型態'\n",
    "#sentence = '私菸案記者會模糊焦點 律師點出華航避談這個重大關鍵'\n",
    "jieba.load_userdict('userdict.txt')\n",
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "for w in jieba.cut(sentence):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用內部資料建立辭典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'那酸'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '那酸民婉君也可報名嗎?'\n",
    "s[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'酸民'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那酸\n",
      "酸民\n",
      "民婉\n",
      "婉君\n",
      "君也\n",
      "也可\n",
      "可報\n",
      "報名\n",
      "名嗎\n",
      "嗎?\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(s) - 2  + 1):\n",
    "    print(s[i:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那酸民\n",
      "酸民婉\n",
      "民婉君\n",
      "婉君也\n",
      "君也可\n",
      "也可報\n",
      "可報名\n",
      "報名嗎\n",
      "名嗎?\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(s) - 3  + 1):\n",
    "    print(s[i:i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(input_sentence, n = 2):\n",
    "    ary = []\n",
    "    for i in range(0, len(input_sentence) - n  + 1):\n",
    "        ary.append(input_sentence[i:i+n])\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那酸', '酸民', '民婉', '婉君', '君也', '也可', '可報', '報名', '名嗎', '嗎?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(s, n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那酸民', '酸民婉', '民婉君', '婉君也', '君也可', '也可報', '可報名', '報名嗎', '名嗎?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(s, n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = '''\n",
    "國安局人員走私菸品案持續延燒，華航昨天開記者會說明，董事長謝世謙鞠躬致歉，但說法卻漏洞百出、避重就輕。律師指出，華航避談核心問題，「何人指示配合機邊交貨、放保稅倉庫」，此人恐有幫助逃漏關稅、走私的責任。\n",
    "\n",
    "謝世謙昨天強調，這次所有交易都在空中飛機上完成，屬於境外交易，所謂「刷卡五筆、幾百萬」並非在國內完成。但有法界人士指出，謝世謙認為菸品案均在機上刷卡，屬於境外交易，但此說法誤導社會大眾，華航屬於國籍航空，尤其空軍一號更是總統專機，即使在機上刷卡，也是屬於我國領土，加上特勤人員在國內預購，交貨犯罪地點也位於桃園機場，如何能算境外？\n",
    "\n",
    "律師翁偉倫指出，若撇除華航是公股航空公司，無論國內、國外或是機上刷卡，客戶要花錢訂購多大量的商品，都是客戶的權利，公司出貨也不會有問題；而華航屬於公股公司，也早有相關規定一人購買菸品的數量，而專機未依菸害防制辦法放寬菸品數量限制，確實有行政疏失，內控有問題需要改善，但此部分均非本案重點。\n",
    "\n",
    "他說，華航昨日記者會內容避重就輕、模糊焦點，如今華航最大的問題是配合機邊交貨，但華航卻避談「是誰指示、核准配合機邊交貨、混入總統專機行李、菸品放入保稅倉庫？」此部分才是牽涉到刑法構成要件，下令指示者有幫助逃漏關稅、幫助走私的責任。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Collections\n",
    "- https://docs.python.org/zh-tw/3/library/collections.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 2: 5, 3: 1, 4: 1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,2,1,2,2,3,4,2]\n",
    "from collections import Counter\n",
    "c = Counter(a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 2), (3, 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('華航', 8),\n",
       " ('菸品', 5),\n",
       " ('屬於', 5),\n",
       " ('，華', 4),\n",
       " ('，但', 4),\n",
       " ('問題', 4),\n",
       " ('交貨', 4),\n",
       " ('機上', 4),\n",
       " ('刷卡', 4),\n",
       " ('走私', 3)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news, n = 2)\n",
    "from collections import Counter\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('，華航', 4),\n",
       " ('謝世謙', 3),\n",
       " ('指出，', 3),\n",
       " ('配合機', 3),\n",
       " ('合機邊', 3),\n",
       " ('機邊交', 3),\n",
       " ('邊交貨', 3),\n",
       " ('機上刷', 3),\n",
       " ('上刷卡', 3),\n",
       " ('刷卡，', 3)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news, n = 3)\n",
    "from collections import Counter\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('配合機邊', 3),\n",
       " ('合機邊交', 3),\n",
       " ('機邊交貨', 3),\n",
       " ('機上刷卡', 3),\n",
       " ('上刷卡，', 3),\n",
       " ('，華航昨', 2),\n",
       " ('避重就輕', 2),\n",
       " ('邊交貨、', 2),\n",
       " ('保稅倉庫', 2),\n",
       " ('有幫助逃', 2)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news, n = 4)\n",
    "from collections import Counter\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentence_ary = re.split('、|，|「|」|？|。|\\n', news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'，美核准上市'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '比特幣期貨，美核准上市'\n",
    "a.replace('比特幣', '').replace('期貨', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeKey(text, keywords):\n",
    "    ret = text\n",
    "    for word in keywords:\n",
    "        ret = ret.replace(word, '')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'期貨，美上市'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeKey(a, ['比特幣','核准'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentence_ary = re.split('、|，|「|」|？|。|\\n', news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('配合機邊', 3), ('合機邊交', 3), ('機邊交貨', 3)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['國安局']\n",
    "words = []\n",
    "for sentence in sentence_ary:\n",
    "    text = removeKey(sentence, keywords)\n",
    "    words.extend(ngram(text, n=4))\n",
    "#print(words)\n",
    "c = Counter(words)\n",
    "c.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['配合機邊',\n",
       " '合機邊交',\n",
       " '機邊交貨',\n",
       " '機上刷卡',\n",
       " '謝世謙',\n",
       " '走私',\n",
       " '菸品',\n",
       " '華航',\n",
       " '指出',\n",
       " '問題',\n",
       " '指示',\n",
       " '交貨',\n",
       " '幫助',\n",
       " '交易',\n",
       " '屬於',\n",
       " '境外',\n",
       " '國內',\n",
       " '專機',\n",
       " '公司']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = []\n",
    "for n in range(4, 1, -1):\n",
    "    words = []\n",
    "    for sentence in sentence_ary:\n",
    "        text = removeKey(sentence, keywords)\n",
    "        words.extend(ngram(text, n = n))\n",
    "    c = Counter(words)\n",
    "    for k,v in c.items():\n",
    "        if v >=3:\n",
    "            keywords.append(k)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLongTermFirst(news):\n",
    "    sentence_ary = re.split('、|，|「|」|？|。|\\n', news)\n",
    "    keywords = []\n",
    "    for n in range(5, 1, -1):\n",
    "        words = []\n",
    "        for sentence in sentence_ary:\n",
    "            text = removeKey(sentence, keywords)\n",
    "            words.extend(ngram(text, n = n))\n",
    "        c = Counter(words)\n",
    "        for k,v in c.items():\n",
    "            if v >=3:\n",
    "                keywords.append(k)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = '''迎戰2020大選，國民黨文傳系統整軍待發，但卻遭爆發言人系統大換將，前主席洪秀柱時代任黨發言人至今的台北市議員王鴻薇與副主委洪孟楷都遭拔發言人職務，周二縣市黨部主委會報介紹發言人已確定不見兩人名字。\n",
    "\n",
    "對此，洪孟楷表示，並不知道是否已遭除名。王鴻薇也說，並未被告知已非黨發言人，但自己原就想請辭，黨有需要再幫忙就好，就像她將與另一黨發言人歐陽龍主持728全代會開閉幕造勢活動，被請辭發言人「沒有關係」。\n",
    "\n",
    "距2020總統與立委選舉剩不到半年，國民黨文宣攻防系統加緊腳步整理砲管，除參考2007與2011總統大選勝選模式，自7月1日起將黨政策會、黨團與智庫架起的三方平台升級為2020選戰PK小組，每周一會決定當周攻防議題，提升攻防火力。\n",
    "\n",
    "文傳會也協助分析每日輿情，找出當日文宣打點與社群媒體發文主題，並組政論節目名嘴群組，提供黨政策論述或大選文宣資料，以利協助議題攻防；還研擬選戰議題說帖，供各縣市黨部、黨籍立委參選人攻防使用，統一選戰口徑，加強火力。\n",
    "\n",
    "此外，文傳會還將成立「新媒體文宣執行策略小組」，協助立委參選人蒐集在地輿情，並進行網路大數據分析，配合中央主要選戰策略，提供相關資料給縣市黨部文宣組與立委參選人使用，力拚國會席次過半。\n",
    "\n",
    "只不過國民黨積極備戰，黨內卻屢傳發言人系統重整、陣前換將。文傳會周二在縣市黨部主委會報中所提供資料也證實，今天2月27日成立的新版「發言人制度」後，近日確實已將任發言人約3年的王鴻薇、洪孟楷除名。\n",
    "\n",
    "目前發言系統僅有1月底到任的首席發言人歐陽龍，2月底出任副發言人的智庫副召集人黃心華與青年黨工洪于茜3人，戰力略顯薄弱。也因此，黨務人士還在周二會議上公開呼籲與會者推薦青年副發言人人選。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['立委參選人',\n",
       " '2020',\n",
       " '黨發言人',\n",
       " '縣市黨部',\n",
       " '國民黨',\n",
       " '發言人',\n",
       " '王鴻薇',\n",
       " '洪孟楷',\n",
       " '文傳會',\n",
       " '大選',\n",
       " '系統',\n",
       " '主委',\n",
       " '周二',\n",
       " '文宣',\n",
       " '攻防',\n",
       " '選戰',\n",
       " '議題',\n",
       " '協助',\n",
       " '提供',\n",
       " '資料']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getLongTermFirst(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = getLongTermFirst(news)\n",
    "with open('userdict.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n')\n",
    "    for w in words:\n",
    "        f.write(w+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字量化分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3, 2: 4, 3: 2}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,1,2,2,1,2,3,3,2]\n",
    "dic = {}\n",
    "for e in a:\n",
    "    if e not in dic:\n",
    "        dic[e] = 1\n",
    "    else:\n",
    "        dic[e] = dic[e] + 1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, 3), (2, 4), (3, 2)])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 2), (1, 3), (2, 4)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dic.items(), key=lambda e: e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 4), (1, 3), (3, 2)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dic.items(), key=lambda e: e[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "dic = {}\n",
    "for w in jieba.cut(news):\n",
    "    if w not in dic:\n",
    "        dic[w] = 1\n",
    "    else:\n",
    "        dic[w] = dic[w] + 1\n",
    "#dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('，', 35),\n",
       " ('\\n', 12),\n",
       " ('發言人', 10),\n",
       " ('。', 10),\n",
       " ('與', 7),\n",
       " ('將', 6),\n",
       " ('的', 6),\n",
       " ('系統', 5),\n",
       " ('攻防', 5),\n",
       " ('縣市黨部', 4)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swd = sorted(dic.items(), key=lambda e: e[1], reverse=True)\n",
    "swd[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'發言人'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ('發言人', 10)\n",
    "k,v = a\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "發言人 10\n",
      "系統 5\n",
      "攻防 5\n",
      "縣市黨部 4\n",
      "文宣 4\n",
      "選戰 4\n",
      "2020 3\n",
      "大選 3\n",
      "國民黨 3\n",
      "黨發言人 3\n",
      "王鴻薇 3\n",
      "洪孟楷 3\n",
      "周二 3\n",
      "議題 3\n"
     ]
    }
   ],
   "source": [
    "for k,v in swd[0:30]:\n",
    "    if len(k) >= 2:\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "發言人 10\n",
      "系統 5\n",
      "攻防 5\n",
      "縣市黨部 4\n",
      "文宣 4\n",
      "選戰 4\n",
      "2020 3\n",
      "大選 3\n",
      "國民黨 3\n",
      "黨發言人 3\n",
      "王鴻薇 3\n",
      "洪孟楷 3\n",
      "周二 3\n",
      "議題 3\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "jieba.load_userdict('userdict.txt')\n",
    "c = Counter(list(jieba.cut(news)))\n",
    "for k,v in c.most_common(30):\n",
    "    if len(k) >= 2:\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "發言人 10\n",
      "系統 5\n",
      "攻防 5\n",
      "縣市黨部 4\n",
      "文宣 4\n",
      "選戰 4\n",
      "大選 3\n",
      "國民黨 3\n",
      "黨發言人 3\n",
      "王鴻薇 3\n",
      "洪孟楷 3\n",
      "周二 3\n",
      "議題 3\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import re\n",
    "from collections import Counter\n",
    "jieba.load_userdict('userdict.txt')\n",
    "c = Counter(list(jieba.cut(news)))\n",
    "for k,v in c.most_common(30):\n",
    "    if len(k) >= 2 and re.match('^[\\u4e00-\\u9fa5]+$', k):\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = '''\n",
    "法國將開始徵收數位服務稅（Digital Service Tax），但我國財政部表示，考量到稅制不同，以及已在現行稅制下針對境外電商課稅等兩項理由，台灣不會跟進課數位服務稅。\n",
    "\n",
    "財政部表示，台灣透過簡化課稅方式，對於數位服務的課稅可說是「領先全球」，且不論營業稅、營利事業所得稅都能課到。\n",
    "\n",
    "資誠稅務諮詢顧問公司表示，雖然法國「數位服務稅」對台商直接影響有限，但若是屬網際網路、數位服務等產業，並以海外使用者為重要收入來源者，應密切關注相關法令變動。\n",
    "\n",
    "法國參議院11日通過新法令，成為歐盟第一個徵收「數位服務稅」國家，並追溯至今年1月1日適用，蘋果、臉書等跨國集團首當其衝。\n",
    "\n",
    "經濟日報提供\n",
    "經濟日報提供\n",
    "但財政部官員表示，首先，歐洲國家稅制與台灣不同，法國等國家判斷課稅權的依據，是根據該公司在境內是否有「固定營業場所」；而台灣課稅權判定則是根據是否有我國來源所得。\n",
    "由於多數提供數位服務的跨國公司，通常不會在當地設有常設機構，對法國等國家而言，就形成租稅漏洞，因此必須透過課徵數位服務稅，藉此來「補破網」。\n",
    "\n",
    "財政部官員解讀，對這些歐洲國家而言應只是暫時性解決方案，事實上，經濟合作發展組織（OECD）已在整合數位稅方案，預計今年10月向G20提出版本，屆時才會有課稅方案。\n",
    "\n",
    "但台灣稅制採「來源法則」，公司如果有我國來源所得就要課稅，對於像是線上訂房網、叫車平台等提供數位服務的境外電商，財政部在現行稅制已有一套課稅方法，該課的稅都課得到。\n",
    "\n",
    "依財政部規定，在中華民國境內無固定營業場所但銷售電子勞務給境內自然人的境外電商，年銷售額只要逾新台幣48萬元者，就須辦理稅籍登記，報繳營業稅。\n",
    "\n",
    "而有了稅籍登記作為基礎，國稅局可推算境外電商在台灣的銷售狀況，境外電商可採核實計算所得額並繳稅外，也可申請按營業項目適用同業利潤標準淨利率計算所得，再根據「利潤貢獻度」，計算應稅所得。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = getLongTermFirst(news)\n",
    "with open('userdict.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n')\n",
    "    for w in words:\n",
    "        f.write(w+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "財政部 6\n",
      "課稅 6\n",
      "台灣 6\n",
      "法國 5\n",
      "數位服務稅 5\n",
      "稅制 5\n",
      "境外電商 5\n",
      "國家 5\n",
      "表示 4\n",
      "公司 4\n",
      "來源 4\n",
      "提供 4\n",
      "所得 4\n",
      "我國 3\n",
      "數位服務的 3\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import re\n",
    "from collections import Counter\n",
    "jieba.load_userdict('userdict.txt')\n",
    "c = Counter(list(jieba.cut(news)))\n",
    "for k,v in c.most_common(30):\n",
    "    if len(k) >= 2 and re.match('^[\\u4e00-\\u9fa5]+$', k):\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, abb, abc = ['a'], ['a', 'b', 'b'], ['a', 'b', 'c']\n",
    "D = [a, abb, abc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('a', a, D)\n",
    "tf = 1 / 1\n",
    "idf = math.log(3/3)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('a', abb, D)\n",
    "tf = 1 / 3\n",
    "idf = math.log(3/3)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('a', abc, D)\n",
    "tf = 1 / 3\n",
    "idf = math.log(3/3)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27031007207210955"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('b', abb, D)\n",
    "tf = 2 / 3\n",
    "idf = math.log(3/2)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13515503603605478"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('b', abc, D)\n",
    "tf = 1 / 3\n",
    "idf = math.log(3/2)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3662040962227032"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf('c', abc, D)\n",
    "tf = 1 / 3\n",
    "idf = math.log(3/1)\n",
    "tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ary = []\n",
    "for doc in D:\n",
    "    if 'c' in doc:\n",
    "        ary.append(doc)\n",
    "len(ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(t, d, D):\n",
    "    tf = d.count(t) / len(d)\n",
    "    idf = math.log(len(D) / len([doc for doc in D if t in doc]))\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('a', a, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('a', abb, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('a', abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27031007207210955"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('b', abb, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13515503603605478"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('b', abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3662040962227032"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('c', abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['財政部', '課稅', '台灣', '法國', '數位服務稅', '稅制', '境外電商', '國家', '來源', '我國']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags(news, 10)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 詞頻矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '柯文哲為了大巨蛋一事，找趙藤雄算帳'\n",
    "b = '柯文哲為了大巨蛋無法舉辦世運會，與趙藤雄對簿公堂'\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'to', 'format', 'my', 'hard', 'disk']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = ['How to format my hard disk', 'Hard disk format problems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disk', 'format', 'hard', 'how', 'my', 'problems', 'to'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set(content[0].lower().split()) | set(content[1].lower().split())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {}\n",
    "word_to_id = {}\n",
    "for idx, w in enumerate(words):\n",
    "    id_to_word[idx]  = w\n",
    "    word_to_id[w] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'hard', 1: 'disk', 2: 'how', 3: 'format', 4: 'problems', 5: 'my', 6: 'to'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hard': 0, 'disk': 1, 'how': 2, 'format': 3, 'problems': 4, 'my': 5, 'to': 6}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m = np.zeros((7,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for w in content[0].lower().split():\n",
    "    m[word_to_id[w], 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for w in content[1].lower().split():\n",
    "    m[word_to_id[w], 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((m[:,0] - m[:,1] ) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disk', 'format', 'hard', 'how', 'my', 'problems', 'to']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 0, 1],\n",
       "       [1, 1, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33471228, 0.33471228, 0.33471228, 0.47042643, 0.47042643,\n",
       "        0.        , 0.47042643],\n",
       "       [0.44832087, 0.44832087, 0.44832087, 0.        , 0.        ,\n",
       "        0.63009934, 0.        ]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
