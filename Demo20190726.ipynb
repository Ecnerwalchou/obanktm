{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "b = 2\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 英文斷詞 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'this is a  book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "print(dir(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function split:\n",
      "\n",
      "split(...) method of builtins.str instance\n",
      "    S.split(sep=None, maxsplit=-1) -> list of strings\n",
      "    \n",
      "    Return a list of the words in S, using sep as the\n",
      "    delimiter string.  If maxsplit is given, at most maxsplit\n",
      "    splits are done. If sep is not specified or is None, any\n",
      "    whitespace string is a separator and empty strings are\n",
      "    removed from the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(s.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'book']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '''\n",
    "今天除了清晨中南部沿海有短暫降雨外，仍是午後雷陣雨為主的天氣型態。氣象預報員陳建安表示，因為太平洋高壓減弱，上半天各地大多為多雲，午後各地山區與近山區都要留意局部大雨跟豪雨的發生機率。加上今天風場偏西南風、水汽較多，北部、東北部地區午後雷陣雨範圍較廣，可能會影響至平地地區，提醒民眾記得攜帶雨具。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n今天除了清晨中南部沿海有短暫降雨外',\n",
       " '仍是午後雷陣雨為主的天氣型態',\n",
       " '氣象預報員陳建安表示',\n",
       " '因為太平洋高壓減弱',\n",
       " '上半天各地大多為多雲',\n",
       " '午後各地山區與近山區都要留意局部大雨跟豪雨的發生機率',\n",
       " '加上今天風場偏西南風',\n",
       " '水汽較多',\n",
       " '北部',\n",
       " '東北部地區午後雷陣雨範圍較廣',\n",
       " '可能會影響至平地地區',\n",
       " '提醒民眾記得攜帶雨具',\n",
       " '\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('，|。|、', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/davidchiu/Desktop/jieba-master.zip\n",
      "  Requirement already satisfied (use --upgrade to upgrade): jieba==0.39 from file:///Users/davidchiu/Desktop/jieba-master.zip in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages\n",
      "Building wheels for collected packages: jieba\n",
      "  Running setup.py bdist_wheel for jieba ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/davidchiu/Library/Caches/pip/wheels/be/21/28/e0bfffcff93e8c8ed12617d1c0e9db29edfe47e8b43e6f17c5\n",
      "Successfully built jieba\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install /Users/davidchiu/Desktop/jieba-master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Tokenizer.cut at 0x103c91f68>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.cut('大巨蛋案對市府同仁下封口令？　柯P否認')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋案\n",
      "對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口\n",
      "令\n",
      "？\n",
      "　\n",
      "柯P\n",
      "否認\n"
     ]
    }
   ],
   "source": [
    "seg = jieba.cut('大巨蛋案對市府同仁下封口令？　柯P否認')\n",
    "for w in seg:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method cut in module jieba:\n",
      "\n",
      "cut(sentence, cut_all=False, HMM=True) method of jieba.Tokenizer instance\n",
      "    The main function that segments an entire sentence that contains\n",
      "    Chinese characters into seperated words.\n",
      "    \n",
      "    Parameter:\n",
      "        - sentence: The str(unicode) to be segmented.\n",
      "        - cut_all: Model type. True for full pattern, False for accurate pattern.\n",
      "        - HMM: Whether to use the Hidden Markov Model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(jieba.cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "?jieba.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 大巨蛋/ 大巨蛋案/ 巨蛋/ 巨蛋案/ 蛋案/ 對/ 市府/ 同仁/ 下/ 封口/ 口令/ / / / 柯/ P/ 否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=True)\n",
    "print(\"Full Mode:\", \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 大巨蛋案/ 對/ 市府/ 同仁/ 下/ 封口/ 令/ ？/ 　/ 柯P/ 否認\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=False, HMM=False)\n",
    "print(\"Default Mode:\", \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '覺得', '這', '個', 'idea', '非常', '的', 'great']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "s = '我覺得這個idea非常的great'\n",
    "list(jieba.cut(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/46/b7dzk4mn6g54qzptv608w7d00000gn/T/jieba.cache\n",
      "Loading model cost 0.691 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 大巨蛋案/ 對/ 市府/ 同仁/ 下/ 封口令/ ？/ 　/ 柯P/ 否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=False)\n",
    "print(\"Default Mode:\", \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋案 N\n",
      "對 P\n",
      "市府 N\n",
      "同仁 N\n",
      "下 POST\n",
      "封口令 n\n",
      "？ x\n",
      "　 x\n",
      "柯P N\n",
      "否認 Vt\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "jieba.load_userdict('userdict.txt')\n",
    "words = pseg.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "for w in words:\n",
    "    print(w.word, w.flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 大巨蛋案/ 對/ 市府/ 同仁/ 下/ 封口令/ ？/ 　/ 柯P/ 否認\n"
     ]
    }
   ],
   "source": [
    "#jieba.add_word('封口令')\n",
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=False)\n",
    "print(\"Default Mode:\", \"/ \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋案 0 4\n",
      "對 4 5\n",
      "市府 5 7\n",
      "同仁 7 9\n",
      "下 9 10\n",
      "封口令 10 13\n",
      "？ 13 14\n",
      "　 14 15\n",
      "柯P 15 17\n",
      "否認 17 19\n"
     ]
    }
   ],
   "source": [
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "words = jieba.tokenize(sentence)\n",
    "\n",
    "for tw in words:\n",
    "    print(tw[0], tw[1], tw[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋案\n",
      "對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口令\n",
      "？\n",
      "　\n",
      "柯P\n",
      "否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "#sentence = '仍是午後雷陣雨為主的天氣型態'\n",
    "#sentence = '私菸案記者會模糊焦點 律師點出華航避談這個重大關鍵'\n",
    "jieba.load_userdict('userdict.txt')\n",
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "for w in jieba.cut(sentence):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用內部資料建立辭典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'那酸'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '那酸民婉君也可報名嗎?'\n",
    "s[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'酸民'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那酸\n",
      "酸民\n",
      "民婉\n",
      "婉君\n",
      "君也\n",
      "也可\n",
      "可報\n",
      "報名\n",
      "名嗎\n",
      "嗎?\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(s) - 2  + 1):\n",
    "    print(s[i:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那酸民\n",
      "酸民婉\n",
      "民婉君\n",
      "婉君也\n",
      "君也可\n",
      "也可報\n",
      "可報名\n",
      "報名嗎\n",
      "名嗎?\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(s) - 3  + 1):\n",
    "    print(s[i:i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(input_sentence, n = 2):\n",
    "    ary = []\n",
    "    for i in range(0, len(input_sentence) - n  + 1):\n",
    "        ary.append(input_sentence[i:i+n])\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那酸', '酸民', '民婉', '婉君', '君也', '也可', '可報', '報名', '名嗎', '嗎?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(s, n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那酸民', '酸民婉', '民婉君', '婉君也', '君也可', '也可報', '可報名', '報名嗎', '名嗎?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(s, n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = '''\n",
    "國安局人員走私菸品案持續延燒，華航昨天開記者會說明，董事長謝世謙鞠躬致歉，但說法卻漏洞百出、避重就輕。律師指出，華航避談核心問題，「何人指示配合機邊交貨、放保稅倉庫」，此人恐有幫助逃漏關稅、走私的責任。\n",
    "\n",
    "謝世謙昨天強調，這次所有交易都在空中飛機上完成，屬於境外交易，所謂「刷卡五筆、幾百萬」並非在國內完成。但有法界人士指出，謝世謙認為菸品案均在機上刷卡，屬於境外交易，但此說法誤導社會大眾，華航屬於國籍航空，尤其空軍一號更是總統專機，即使在機上刷卡，也是屬於我國領土，加上特勤人員在國內預購，交貨犯罪地點也位於桃園機場，如何能算境外？\n",
    "\n",
    "律師翁偉倫指出，若撇除華航是公股航空公司，無論國內、國外或是機上刷卡，客戶要花錢訂購多大量的商品，都是客戶的權利，公司出貨也不會有問題；而華航屬於公股公司，也早有相關規定一人購買菸品的數量，而專機未依菸害防制辦法放寬菸品數量限制，確實有行政疏失，內控有問題需要改善，但此部分均非本案重點。\n",
    "\n",
    "他說，華航昨日記者會內容避重就輕、模糊焦點，如今華航最大的問題是配合機邊交貨，但華航卻避談「是誰指示、核准配合機邊交貨、混入總統專機行李、菸品放入保稅倉庫？」此部分才是牽涉到刑法構成要件，下令指示者有幫助逃漏關稅、幫助走私的責任。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Collections\n",
    "- https://docs.python.org/zh-tw/3/library/collections.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 2: 5, 3: 1, 4: 1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,2,1,2,2,3,4,2]\n",
    "from collections import Counter\n",
    "c = Counter(a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 2), (3, 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('華航', 8),\n",
       " ('菸品', 5),\n",
       " ('屬於', 5),\n",
       " ('，華', 4),\n",
       " ('，但', 4),\n",
       " ('問題', 4),\n",
       " ('交貨', 4),\n",
       " ('機上', 4),\n",
       " ('刷卡', 4),\n",
       " ('走私', 3)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news, n = 2)\n",
    "from collections import Counter\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('，華航', 4),\n",
       " ('謝世謙', 3),\n",
       " ('指出，', 3),\n",
       " ('配合機', 3),\n",
       " ('合機邊', 3),\n",
       " ('機邊交', 3),\n",
       " ('邊交貨', 3),\n",
       " ('機上刷', 3),\n",
       " ('上刷卡', 3),\n",
       " ('刷卡，', 3)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news, n = 3)\n",
    "from collections import Counter\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('配合機邊', 3),\n",
       " ('合機邊交', 3),\n",
       " ('機邊交貨', 3),\n",
       " ('機上刷卡', 3),\n",
       " ('上刷卡，', 3),\n",
       " ('，華航昨', 2),\n",
       " ('避重就輕', 2),\n",
       " ('邊交貨、', 2),\n",
       " ('保稅倉庫', 2),\n",
       " ('有幫助逃', 2)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ngram(news, n = 4)\n",
    "from collections import Counter\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentence_ary = re.split('、|，|「|」|？|。|\\n', news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'，美核准上市'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '比特幣期貨，美核准上市'\n",
    "a.replace('比特幣', '').replace('期貨', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeKey(text, keywords):\n",
    "    ret = text\n",
    "    for word in keywords:\n",
    "        ret = ret.replace(word, '')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'期貨，美上市'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeKey(a, ['比特幣','核准'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentence_ary = re.split('、|，|「|」|？|。|\\n', news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('配合機邊', 3), ('合機邊交', 3), ('機邊交貨', 3)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['國安局']\n",
    "words = []\n",
    "for sentence in sentence_ary:\n",
    "    text = removeKey(sentence, keywords)\n",
    "    words.extend(ngram(text, n=4))\n",
    "#print(words)\n",
    "c = Counter(words)\n",
    "c.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['配合機邊',\n",
       " '合機邊交',\n",
       " '機邊交貨',\n",
       " '機上刷卡',\n",
       " '謝世謙',\n",
       " '走私',\n",
       " '菸品',\n",
       " '華航',\n",
       " '指出',\n",
       " '問題',\n",
       " '指示',\n",
       " '交貨',\n",
       " '幫助',\n",
       " '交易',\n",
       " '屬於',\n",
       " '境外',\n",
       " '國內',\n",
       " '專機',\n",
       " '公司']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = []\n",
    "for n in range(4, 1, -1):\n",
    "    words = []\n",
    "    for sentence in sentence_ary:\n",
    "        text = removeKey(sentence, keywords)\n",
    "        words.extend(ngram(text, n = n))\n",
    "    c = Counter(words)\n",
    "    for k,v in c.items():\n",
    "        if v >=3:\n",
    "            keywords.append(k)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLongTermFirst(news):\n",
    "    sentence_ary = re.split('、|，|「|」|？|。|\\n', news)\n",
    "    keywords = []\n",
    "    for n in range(5, 1, -1):\n",
    "        words = []\n",
    "        for sentence in sentence_ary:\n",
    "            text = removeKey(sentence, keywords)\n",
    "            words.extend(ngram(text, n = n))\n",
    "        c = Counter(words)\n",
    "        for k,v in c.items():\n",
    "            if v >=3:\n",
    "                keywords.append(k)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = '''迎戰2020大選，國民黨文傳系統整軍待發，但卻遭爆發言人系統大換將，前主席洪秀柱時代任黨發言人至今的台北市議員王鴻薇與副主委洪孟楷都遭拔發言人職務，周二縣市黨部主委會報介紹發言人已確定不見兩人名字。\n",
    "\n",
    "對此，洪孟楷表示，並不知道是否已遭除名。王鴻薇也說，並未被告知已非黨發言人，但自己原就想請辭，黨有需要再幫忙就好，就像她將與另一黨發言人歐陽龍主持728全代會開閉幕造勢活動，被請辭發言人「沒有關係」。\n",
    "\n",
    "距2020總統與立委選舉剩不到半年，國民黨文宣攻防系統加緊腳步整理砲管，除參考2007與2011總統大選勝選模式，自7月1日起將黨政策會、黨團與智庫架起的三方平台升級為2020選戰PK小組，每周一會決定當周攻防議題，提升攻防火力。\n",
    "\n",
    "文傳會也協助分析每日輿情，找出當日文宣打點與社群媒體發文主題，並組政論節目名嘴群組，提供黨政策論述或大選文宣資料，以利協助議題攻防；還研擬選戰議題說帖，供各縣市黨部、黨籍立委參選人攻防使用，統一選戰口徑，加強火力。\n",
    "\n",
    "此外，文傳會還將成立「新媒體文宣執行策略小組」，協助立委參選人蒐集在地輿情，並進行網路大數據分析，配合中央主要選戰策略，提供相關資料給縣市黨部文宣組與立委參選人使用，力拚國會席次過半。\n",
    "\n",
    "只不過國民黨積極備戰，黨內卻屢傳發言人系統重整、陣前換將。文傳會周二在縣市黨部主委會報中所提供資料也證實，今天2月27日成立的新版「發言人制度」後，近日確實已將任發言人約3年的王鴻薇、洪孟楷除名。\n",
    "\n",
    "目前發言系統僅有1月底到任的首席發言人歐陽龍，2月底出任副發言人的智庫副召集人黃心華與青年黨工洪于茜3人，戰力略顯薄弱。也因此，黨務人士還在周二會議上公開呼籲與會者推薦青年副發言人人選。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['立委參選人',\n",
       " '2020',\n",
       " '黨發言人',\n",
       " '縣市黨部',\n",
       " '國民黨',\n",
       " '發言人',\n",
       " '王鴻薇',\n",
       " '洪孟楷',\n",
       " '文傳會',\n",
       " '大選',\n",
       " '系統',\n",
       " '主委',\n",
       " '周二',\n",
       " '文宣',\n",
       " '攻防',\n",
       " '選戰',\n",
       " '議題',\n",
       " '協助',\n",
       " '提供',\n",
       " '資料']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getLongTermFirst(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
