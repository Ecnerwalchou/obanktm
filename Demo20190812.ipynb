{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 詞庫手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('trunk.n.01'),\n",
       " Synset('trunk.n.02'),\n",
       " Synset('torso.n.01'),\n",
       " Synset('luggage_compartment.n.01'),\n",
       " Synset('proboscis.n.02')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('trunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計數手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'you say goodbye and I say hello. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'say', 6: 'hello.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "text = s\n",
    "text = text.lower()\n",
    "words = text.split()\n",
    "words_to_id = {}\n",
    "id_to_words = {}\n",
    "for idx, word in enumerate(words):\n",
    "    words_to_id[word] = idx\n",
    "    id_to_words[idx] = word\n",
    "words_to_id\n",
    "id_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = create_co_matrix(corpus, vocab_size)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
    "    return np.dot(nx, ny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0 = C[word_to_id['you']]\n",
    "c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = C[word_to_id['i']]\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067691154799"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity(c0, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cs = cosine_similarity(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    \n",
    "    # 1. 列出Query\n",
    "    if query not in word_to_id:\n",
    "        print('%s is not found' % query)\n",
    "        return\n",
    "\n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # 2. 計算Cosine Similarity\n",
    "    vocab_size = len(id_to_word)\n",
    "\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "    # 3. 從cosine similarity 由高到低列出數值結果\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "most_similar('you', word_to_id, id_to_word, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "cs = cosine_distances(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodbye 0.29289321881345254\n",
      "i 0.29289321881345254\n",
      "hello 0.29289321881345254\n",
      "say 1.0\n",
      "and 1.0\n"
     ]
    }
   ],
   "source": [
    "for idx in cs[0].argsort()[1:6]:\n",
    "    print(id_to_word[idx], cs[0][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% done' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = ppmi(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 1.8073549, 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [1.8073549, 0.       , 0.8073549, 0.       , 0.8073549, 0.8073549,\n",
       "        0.       ],\n",
       "       [0.       , 0.8073549, 0.       , 1.8073549, 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 1.8073549, 0.       , 1.8073549, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.8073549, 0.       , 1.8073549, 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.8073549, 0.       , 0.       , 0.       , 0.       ,\n",
       "        2.807355 ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 2.807355 ,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "U, S, V = np.linalg.svd(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 7), (7,), (7, 7))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, S.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "from matplotlib import pyplot as plt\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "house_X = np.array([30, 300, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 30, 300,  10])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_W = np.array([[70], [-1], [-6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70],\n",
       "       [-1],\n",
       "       [-6]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1740])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(house_X, house_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(x):\n",
    "    return 1/ (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99752738, 0.99999774, 1.        ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([1,2]) # (2)\n",
    "W = np.array([[1,3,5],[2,4,6]]) # (2 , 3)\n",
    "B = np.array([1,2,3])\n",
    "\n",
    "Y = np.dot(X,W) + B# (3)\n",
    "\n",
    "A = sigmoid_function(Y)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.99752059, 13.9950457 ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = np.array([[1,2],[3,4],[5,6]]) # (3 , 2)\n",
    "B1 = np.array([1,2])\n",
    "Y1 = np.dot(A, W1) + B1\n",
    "Y1 # (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22411671, -0.42337363,  0.30125317],\n",
       "       [-0.90864496,  2.42151804, -0.98993779],\n",
       "       [-0.16548563, -1.11887548,  0.45773035],\n",
       "       [-0.41049857, -2.28458649, -0.8766367 ],\n",
       "       [ 0.28536285, -1.97796828,  0.06823124],\n",
       "       [-0.32297675, -0.96620916, -0.61939916],\n",
       "       [ 0.32924283, -0.20302245, -1.1959254 ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.randn(7, 3)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22411671 -0.42337363  0.30125317]]\n"
     ]
    }
   ],
   "source": [
    "h = np.dot(c,W)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.690989   -2.35342418 -0.9818263   1.4413382  -1.36603427  0.44567065\n",
      "   0.58484311]]\n"
     ]
    }
   ],
   "source": [
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
    "\n",
    "W_in  = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03511903, 0.25949646, 0.70538451])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_function(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "softmax_function(numpy.array([-1,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]] [1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "contexts, target = create_contexts_target(corpus, 1)\n",
    "print(contexts, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "    N = corpus.shape[0]\n",
    "\n",
    "    if corpus.ndim == 1:\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
    "        for idx, word_id in enumerate(corpus):\n",
    "            one_hot[idx, word_id] = 1\n",
    "    elif corpus.ndim == 2:\n",
    "        C = corpus.shape[1]\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "        for idx_0, word_ids in enumerate(corpus):\n",
    "            for idx_1, word_id in enumerate(word_ids):\n",
    "                one_hot[idx_0, idx_1, word_id] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, target = create_contexts_target(corpus, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 3],\n",
       "       [2, 4],\n",
       "       [3, 1],\n",
       "       [4, 5],\n",
       "       [1, 6]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 1, 5])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 7)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = softmax(x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = self.out * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.out * sumdx\n",
    "        return dx\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.y = None  \n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "\n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "\n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx / batch_size\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx\n",
    "\n",
    "\n",
    "class SigmoidWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.loss = None\n",
    "        self.y = None \n",
    "        self.t = None \n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "        self.loss = cross_entropy_error(np.c_[1 - self.y, self.y], self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = (self.y - self.t) * dout / batch_size\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.params, self.grads = [], []\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask\n",
    "\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "\n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dW, = self.grads\n",
    "        dW[...] = 0\n",
    "        np.add.at(dW, self.idx, dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "        h1 = self.in_layer1.forward(contexts[:, 1])\n",
    "        h = (h0 + h1) * 0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "hidden_size = 5\n",
    "model = SimpleCBOW(vocab_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    '''\n",
    "    Adam (http://arxiv.org/abs/1412.6980v8)\n",
    "    '''\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in params:\n",
    "                self.m.append(np.zeros_like(param))\n",
    "                self.v.append(np.zeros_like(param))\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
    "            \n",
    "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate(params, grads):\n",
    "    params, grads = params[:], grads[:]  # copy list\n",
    "\n",
    "    while True:\n",
    "        find_flg = False\n",
    "        L = len(params)\n",
    "\n",
    "        for i in range(0, L - 1):\n",
    "            for j in range(i + 1, L):\n",
    "                if params[i] is params[j]:\n",
    "                    grads[i] += grads[j]  \n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
    "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
    "                    grads[i] += grads[j].T\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "\n",
    "                if find_flg: break\n",
    "            if find_flg: break\n",
    "\n",
    "        if not find_flg: break\n",
    "\n",
    "    return params, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_list = []\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "       \n",
    "            idx = numpy.random.permutation(numpy.arange(data_size))\n",
    "            x = x[idx]\n",
    "            t = t[idx]\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "\n",
    "              \n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    avg_loss = total_loss / loss_count\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| epoch %d |  iter %d / %d | time %d[s] | loss %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
    "                    self.loss_list.append(float(avg_loss))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = numpy.arange(len(self.loss_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.loss_list, label='train')\n",
    "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x - x.max(axis=1, keepdims=True)\n",
    "        x = np.exp(x)\n",
    "        x /= x.sum(axis=1, keepdims=True)\n",
    "    elif x.ndim == 1:\n",
    "        x = x - np.max(x)\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2621 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 2622 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 2623 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 2624 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 2625 |  iter 1 / 2 | time 0[s] | loss 0.01\n",
      "| epoch 2626 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 2627 |  iter 1 / 2 | time 0[s] | loss 0.13\n",
      "| epoch 2628 |  iter 1 / 2 | time 0[s] | loss 0.13\n",
      "| epoch 2629 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 2630 |  iter 1 / 2 | time 0[s] | loss 0.24\n"
     ]
    }
   ],
   "source": [
    "window_size = 1\n",
    "batch_size = 3\n",
    "max_epoch = 10\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you [-3.0197244  -0.66500604  0.9788965  -2.5115094  -2.4862497 ]\n",
      "say [ 1.9274521  1.0592844 -1.6078502  1.6223705  1.2155228]\n",
      "goodbye [ 0.62380654 -2.0771635   1.9081205  -0.01204651 -0.02666894]\n",
      "and [-0.05161366  3.0025125   1.2629162   2.173613    2.9995368 ]\n",
      "i [ 0.6256028  -2.063149    1.9175583  -0.01632257 -0.02905285]\n",
      "hello [-3.0255537 -0.6577454  0.9786197 -2.4892027 -2.4912066]\n",
      ". [ 2.7054768  -1.4704615  -3.0654788  -0.09320928 -1.3341477 ]\n"
     ]
    }
   ],
   "source": [
    "word_vecs = model.word_vecs\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['you']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.0197244 , -0.66500604,  0.9788965 , -2.5115094 , -2.4862497 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you 0.0\n",
      "say 1.9328661\n",
      "goodbye 0.8944926\n",
      "and 1.5714283\n",
      "i 0.8935633\n",
      "hello 1.2218952e-05\n",
      ". 1.3045679\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    cs = cosine_distances([word_vecs[0], word_vecs[i]])\n",
    "    print(id_to_word[i],cs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
